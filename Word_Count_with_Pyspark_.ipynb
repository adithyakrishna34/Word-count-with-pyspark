{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlDvj2x9FQRI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23MBD014\n"
      ],
      "metadata": {
        "id": "a5oGBnCJFcCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enabling Technologies for Data Science -II"
      ],
      "metadata": {
        "id": "7DvnhcM2FlWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical No.1"
      ],
      "metadata": {
        "id": "4VXlGPrKFr5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Count with PySpark\n"
      ],
      "metadata": {
        "id": "JT5z0cQnVz0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RkFpNxKFwHT",
        "outputId": "4e47c403-bda7-4a3c-e273-c8fe5bb94e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext"
      ],
      "metadata": {
        "id": "slvDuFm7F-M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setAppName(\"PySparkWordCount\").setMaster(\"local\")\n",
        "sc=SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "u7kJ0ml6GXqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "08a77533-c80e-4f12-9658-9b5312335912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkWordCount, master=local) created by __init__ at <ipython-input-3-15c0ca770b89>:2 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-15c0ca770b89>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySparkWordCount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=PySparkWordCount, master=local) created by __init__ at <ipython-input-3-15c0ca770b89>:2 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_shikha=[\"hello world\",\"hello spark\",\"hello RDD\",\"hello PySpark\",\"hello shikha\"]\n",
        "rdd_shikha=sc.parallelize(data_shikha)"
      ],
      "metadata": {
        "id": "hVfhX2bgF-b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd_shikha.collect())"
      ],
      "metadata": {
        "id": "fEvGZPZnF_Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_rdd_shikha=rdd_shikha.flatMap(lambda sentence: sentence.split(\" \"))"
      ],
      "metadata": {
        "id": "p6LSm9CsF_Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_rdd_shikha.collect())"
      ],
      "metadata": {
        "id": "jS8G3lOxF_Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_pairs_rdd_shikha=words_rdd_shikha.map(lambda word: (word, 1))"
      ],
      "metadata": {
        "id": "3uE-hWbqF_PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_pairs_rdd_shikha=words_rdd_shikha.map(lambda word: (word, 1))"
      ],
      "metadata": {
        "id": "KRw8wxalHzcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_pairs_rdd_shikha.collect())"
      ],
      "metadata": {
        "id": "_z_XqkJ9IAKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_counts_rdd_shikha=words_pairs_rdd_shikha.reduceByKey(lambda a,b: a+b)"
      ],
      "metadata": {
        "id": "VE93bfG8IJnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_counts_rdd_shikha.collect())"
      ],
      "metadata": {
        "id": "W8i0RGnIF_SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_counts_shikha=words_counts_rdd_shikha.collect()"
      ],
      "metadata": {
        "id": "VXxp-FkkF_Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_counts_shikha)"
      ],
      "metadata": {
        "id": "ZTmWVmf4F_Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in words_counts_shikha:\n",
        "  print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "EmUkT27rF_Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop() #Stop the Spark context"
      ],
      "metadata": {
        "id": "Nq7BJjF5F_di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23MBD014"
      ],
      "metadata": {
        "id": "9luD-wRwLFtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enabling Technologies for Data Science-II"
      ],
      "metadata": {
        "id": "E9b_2Z_1LFwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical NO.2"
      ],
      "metadata": {
        "id": "iTiRjDLnLFzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature Conversion with PySpark"
      ],
      "metadata": {
        "id": "VwUiEwZKLF2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PySpark"
      ],
      "metadata": {
        "id": "I44H6C2pLa5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf"
      ],
      "metadata": {
        "id": "hFN-q9PaLa8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf=SparkConf().setAppName(\"PySparkTemperatureConversion\").setMaster(\"local\")\n",
        "sc=SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "n9yVicWeLa_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "celsius_temps_shikha=[0,20,30,40,100]\n",
        "rdd=sc.parallelize(celsius_temps_shikha)"
      ],
      "metadata": {
        "id": "KWrxpWSaLbBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fahrenheit_rdd_shikha=rdd.map(lambda c: (c, (c *9/5)+32))"
      ],
      "metadata": {
        "id": "CIRpijebLbD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fahrenheit_rdd_shikha.collect())"
      ],
      "metadata": {
        "id": "B7Ad9N2ULbGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fahrenheit_temps_shikha=fahrenheit_rdd_shikha.collect()"
      ],
      "metadata": {
        "id": "e9MLa6FpLbI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fahrenheit_temps_shikha)"
      ],
      "metadata": {
        "id": "1A8TEAtaLbMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c, f in fahrenheit_temps_shikha:\n",
        "  print(f\"{c} Celsius is equal to {f} Fahrenheit\")"
      ],
      "metadata": {
        "id": "RC0Lxg8vMcGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "M5tpKJu9McIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23MBD014"
      ],
      "metadata": {
        "id": "_OU-w-oMNz8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enabling Technologies for Data Science - II"
      ],
      "metadata": {
        "id": "zftxLH6AN0Qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical No.3"
      ],
      "metadata": {
        "id": "gfDEeB1YN0eA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark Analysis on Iris Dataset"
      ],
      "metadata": {
        "id": "jgs8UyEkN-H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "YW2o9FUcOFVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "DlOuhdM5OFX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"IrisDatasetExample\").getOrCreate()"
      ],
      "metadata": {
        "id": "eXCGSEeqOFaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data_shikha = [\n",
        "(5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"),\n",
        "(4.9, 3.0, 1.4, 0.2, \"Iris-setosa\"),\n",
        "(4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"),\n",
        "(7.0, 3.2, 4.7, 1.4, \"Iris-versicolor\"),\n",
        "(6.4, 3.2, 4.5, 1.5, \"Iris-versicolor\"),\n",
        "(6.9, 3.1, 4.9, 1.5, \"Iris-versicolor\"),\n",
        "(5.9, 3.0, 5.1, 1.8, \"Iris-virginica\"),\n",
        "(6.8, 3.0, 5.5, 2.1, \"Iris-virginica\"),\n",
        "(6.7, 3.1, 5.6, 2.4, \"Iris-virginica\")\n",
        "]"
      ],
      "metadata": {
        "id": "TCT0IsuGOFc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_shikha= [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]"
      ],
      "metadata": {
        "id": "CWoJF-clOFfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha = spark.createDataFrame(iris_data_shikha, schema=columns_adithya)"
      ],
      "metadata": {
        "id": "Q1hMJFQbOFhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha.show()"
      ],
      "metadata": {
        "id": "Sy7qBFEQOFj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered_shikha = df_shikha.filter(col(\"species\") == \"Iris-setosa\")"
      ],
      "metadata": {
        "id": "x5vjAIpqOFmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered_shikha.show()"
      ],
      "metadata": {
        "id": "_zjBtIx_OFow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "4EAC8tT_OFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23MBD014"
      ],
      "metadata": {
        "id": "EMKALcMfRWnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enabling Technologies for Data Science - II"
      ],
      "metadata": {
        "id": "4N2a5xzmRWvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical No.4"
      ],
      "metadata": {
        "id": "YKea6ftuRW25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark Analysis on Wine Quality Dataset"
      ],
      "metadata": {
        "id": "rthxD_0GRXAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "tTYeeD6ZOFt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "3_kBm28fRkjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_shikha = SparkSession.builder.appName(\"WineQualityAnalyzer\").getOrCreate()"
      ],
      "metadata": {
        "id": "rfDUm0mKRkml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_shikha"
      ],
      "metadata": {
        "id": "IUe2szhYRkpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha = spark_shikha.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(\"/content/winequality-red.csv\")"
      ],
      "metadata": {
        "id": "NF3C0x6NRkrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha.show(5)"
      ],
      "metadata": {
        "id": "eoQsaLIwRkug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha_filtered_shikha= df_shikha.filter(col(\"quality\") >= 7)"
      ],
      "metadata": {
        "id": "nAvMKx-vRkxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_shikha_filtered_shikha.show()"
      ],
      "metadata": {
        "id": "iFsuFLaSOFxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "WPIevuPzR4Ay"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}